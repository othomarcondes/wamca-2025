% Intended LaTeX compiler: pdflatex
\documentclass[conference, 10pt, final]{IEEEtran}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usepackage[T1]{fontenc}
\usepackage{breakurl}
\usepackage{xspace}
\usepackage{listings}
\usepackage[font=footnotesize]{subfig}
\newcommand{\prettysmall}{\fontsize{4}{6}\selectfont}
\newcommand{\pstwo}{\fontsize{8}{8}\selectfont}
\usepackage{color,colortbl,xcolor}
\definecolor{dgeqrtC}{HTML}{e41a1c}
\definecolor{dlarfbC}{HTML}{377eb8}
\definecolor{dtpqrtC}{HTML}{4daf4a}
\definecolor{dtpmqrtC}{HTML}{984ea3}
\newcommand{\dgeqrtcolor}{red}
\newcommand{\dlarfbcolor}{blue}
\newcommand{\dtpqrtcolor}{green}
\newcommand{\dtpmqrtcolor}{purple}
\lstdefinestyle{customc}{morekeywords={DGEQRT },keywordstyle=\color{dgeqrtC},morekeywords=[2]{DLARFB},keywordstyle=[2]\color{dlarfbC},morekeywords=[3]{DTPQRT},keywordstyle=[3]\color{dtpqrtC},morekeywords=[4]{DTPMQRT},keywordstyle=[4]\color{dtpmqrtC}, numbers=left, breakatwhitespace=false,        breaklines=true,captionpos=b,keepspaces=true,numbersep=5pt,showspaces=false,showstringspaces=false,showtabs=false,tabsize=2}
\lstset{ basicstyle=\ttfamily\small, breaklines=true, columns=fullflexible,numbers=left,numberstyle=\tiny\color{gray}, xleftmargin=10pt,flexiblecolumns=false}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{tikz}
\usetikzlibrary{automata,arrows,positioning,calc}
\usepackage{subfig}
\newcommand{\subfigureautorefname}{Figure} % allows autoref to find subimages.
\date{}
\title{LU-factor}
\hypersetup{
 pdfauthor={Otho José Sirtoli Marcondes, Lucas Mello Schnorr},
 pdftitle={LU-factor},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 28.1 (Org mode 9.7.26)}, 
 pdflang={Portuges}}
\begin{document}


\title{???}
% Let's keep the next title for the official post-WSPPD publication
% Visual Performance Analysis of Memory Operations in Heterogeneous Task-Based Applications}

\author{
\IEEEauthorblockN{Otho José Sirtoli Marcondes\IEEEauthorrefmark{1},
                  Lucas Mello Schnorr\IEEEauthorrefmark{1}}
\IEEEauthorblockN{\IEEEauthorrefmark{1} Institute of Informatics/PPGC/UFRGS, Porto Alegre, Brazil}
}

\maketitle

\newcommand{\kiter}{K Iteration}
\begin{abstract}
\end{abstract}
\section{Introduction}
\label{sec:orgec14744}
High-Performance Computing (HPC) systems, particularly computing clusters, are essential for solving large-scale scientific and engineering problems. These clusters consist of multiple interconnected nodes, each with its own processor units and memory. In order to maximize application performance on clusters, it is essential to consider both inter-node communication efficiency and workload balance across the computing nodes.

A crucial aspect of achieving efficient parallel performance is data partitioning, which determines how data is divided and distributed across the computing nodes. Among various strategies, static data partitioning is commonly used due to its simplicity and low runtime overhead. One of the examples of static data distribution is the block-cyclic (BC) distribution, a method that was popularized by the ScaLAPACK \cite{blackford1997scalapack} library.

This paper focuses on a scenario that combines static data partitioning with dynamic task scheduling. By leveraging task-based runtimes, we aim to dynamically schedule tasks at runtime while maintaining a static block layout of data. This approach enables better adaptability to runtime variations, such as load imbalance and communication delays, while preserving the advantages of a static data map.

As a case study, we explore the LU factorization, a fundamental operation in linear algebra widely used in scientific computing. We adopt a block cyclic distribution scheme for the input matrix, a method that balances the computational load and spreads data evenly across processes. Our goal is to evaluate how dynamic scheduling of tasks can improve the performance of LU factorization in clusters.

Throughout the development of this work, several challenges were encountered related to the use of MPI for executing applications across multiple nodes. These included: configuration challenges with Guix for package management across distributed nodes; issues related to the TCP interface in the MPI NewMadeleine implementation; and errors when using StarVZ \cite{pinto2021providing} visualization framework with the traces collected from the executions (still not resolved).

The paper is structured as follows. Section\textasciitilde{}\ref{sec:related} presents some related work on matrix distribution and modern task-based runtimes. Section\textasciitilde{}\ref{sec:methodology} details our methodology and explains how we conducted the experiments in our investigation. Section\textasciitilde{}\ref{sec:results} presents the experiments and their results. Section\textasciitilde{}\ref{sec:conclusion} concludes this work with some considerations.
\section{Related Work}
\label{sec:related}
\section{Experimental Methodology}
\label{sec:methodology}
\section{Results}
\label{sec:results}
\section{Conclusion}
\label{sec:conclusion}
\section*{Acknowledgements}

The experiments in this work used the PCAD infrastructure, \url{http://gppd-hpc.inf.ufrgs.br}, at INF/UFRGS.
\clearpage

\bibliographystyle{IEEEtran}
\bibliography{refs}
\end{document}
